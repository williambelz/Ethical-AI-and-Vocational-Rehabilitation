---
title: "Additional Case Studies"
description: "More real-world examples of ethical AI in vocational rehabilitation"
sidebar_position: 2
slug: "/additional-case-studies"
---

# Additional Case Studies

This page expands on the examples listed in the README by providing three more case studies. Each opens with a quick summary of takeaways followed by a short explanation of what happened and why it matters.

## Case Study 1: Accessible Resume Screener

**Key Points**
- Automated resume screener used by a mid-sized recruiting firm
- Initial deployment lacked alt text and keyboard navigation
- After accessibility audit, interface redesigned to meet WCAG 2.2 AA requirements
- Inclusion of diverse applicant data reduced bias in candidate scoring

**Explanation**
The recruiting firm adopted an AI tool to filter job applicants. Early user testing showed screen-reader users could not navigate the forms, violating [ACCESSIBILITY_REQUIREMENTS](../ACCESSIBILITY_REQUIREMENTS.md). Developers added semantic labels and ensured sufficient color contrast. They also re-trained the model with a dataset that included applicants with varied employment histories, resulting in improved fairness and compliance.

## Case Study 2: Predictive Retention Modeling in State VR Program

**Key Points**
- State agency used machine learning to predict which clients might drop out of training
- Counselors received risk scores with explanatory text
- Transparent model allowed clients to challenge inaccurate predictions
- Drop-out rate decreased by 12% over one year

**Explanation**
A state vocational rehabilitation program built a predictive model using anonymized case records. Each prediction came with a plain-language summary so counselors could discuss results with clients. The team monitored outcomes and updated the model quarterly. Providing clear reasoning and an appeals process increased trust among participants and improved retention.

## Case Study 3: Adaptive VR Workplace Simulation

**Key Points**
- University research project used AI to adjust simulation difficulty in real time
- Participants with traumatic brain injuries received personalized prompts
- Feedback from therapists shaped algorithm updates
- Study emphasized accessible design to avoid sensory overload

**Explanation**
Researchers developed a VR workplace simulator that modifies tasks based on user performance. To meet accessibility goals, all text alternatives and captions followed the repository's requirements. Therapists noted that adjustable pacing helped reduce cognitive strain. By combining human oversight with adaptive algorithms, the project demonstrated a successful approach to inclusive VR training.

## Case Study 4: Walmart's VR Training Program

**Key Points**
- Large retail chain partnered with Strivr to teach associates how to handle busy shopping days
- Training sessions collect performance metrics under a strict privacy policy
- Reported decrease in onboarding time and improved confidence among new hires

**Explanation**
Walmart rolled out headsets so employees could practice scenarios like Black Friday crowds. The company worked with Strivr to keep usage data anonymous and participation voluntary. Clear communication about metrics addressed surveillance concerns while still measuring effectiveness. [Strivr's case study](https://www.strivr.com/walmart-case-study/) provides additional details.

## Case Study 5: Bravemind PTSD Therapy

**Key Points**
- Developed by the University of Southern California's Institute for Creative Technologies
- Immersive environments help veterans revisit traumatic memories in a controlled setting
- Sessions require licensed clinicians and explicit informed consent

**Explanation**
Bravemind exposes participants to tailored VR scenes while therapists monitor reactions and adjust intensity. Ethical guidelines mandate voluntary participation and clinical oversight to minimize distress. Studies show meaningful symptom reduction for many veterans. More information is available on the [USC ICT website](https://ict.usc.edu/prototypes/bravemind/).

## Case Study 6: Harassment in Social VR Platforms

**Key Points**
- Testers in Meta's Horizon Worlds reported incidents of virtual harassment
- Platform responded by implementing personal boundary features
- Highlights the importance of clear community standards in VR spaces

**Explanation**
Early adopters of Horizon Worlds described unwanted contact from other avatars, prompting discussion about moderating social VR. Meta added safety tools like default distance buffers and easier reporting. This episode shows that ethical VR design must address user behavior along with technical accessibility. [The Verge](https://www.theverge.com/2021/12/16/22839010/meta-horizon-worlds-vr-harassment-virtual-reality) summarizes the controversy.

## Additional Links

- [Strivr Walmart Case Study](https://www.strivr.com/walmart-case-study/)
- [USC ICT Bravemind Project](https://ict.usc.edu/prototypes/bravemind/)
- [The Verge on Horizon Worlds Harassment](https://www.theverge.com/2021/12/16/22839010/meta-horizon-worlds-vr-harassment-virtual-reality)

