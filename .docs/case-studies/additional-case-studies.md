---
title: "Additional Case Studies"
description: "More real-world examples of ethical AI in vocational rehabilitation"
sidebar_position: 2
slug: "/additional-case-studies"
---

# Additional Case Studies

This page expands on the examples listed in the README by providing three more case studies. Each opens with a quick summary of takeaways followed by a short explanation of what happened and why it matters.

## Case Study 1: Accessible Resume Screener

**Key Points**
- Automated resume screener used by a mid-sized recruiting firm
- Initial deployment lacked alt text and keyboard navigation
- After accessibility audit, interface redesigned to meet WCAG 2.2 AA requirements
- Inclusion of diverse applicant data reduced bias in candidate scoring

**Explanation**
The recruiting firm adopted an AI tool to filter job applicants. Early user testing showed screen-reader users could not navigate the forms, violating [ACCESSIBILITY_REQUIREMENTS](../ACCESSIBILITY_REQUIREMENTS.md). Developers added semantic labels and ensured sufficient color contrast. They also re-trained the model with a dataset that included applicants with varied employment histories, resulting in improved fairness and compliance.

## Case Study 2: Predictive Retention Modeling in State VR Program

**Key Points**
- State agency used machine learning to predict which clients might drop out of training
- Counselors received risk scores with explanatory text
- Transparent model allowed clients to challenge inaccurate predictions
- Drop-out rate decreased by 12% over one year

**Explanation**
A state vocational rehabilitation program built a predictive model using anonymized case records. Each prediction came with a plain-language summary so counselors could discuss results with clients. The team monitored outcomes and updated the model quarterly. Providing clear reasoning and an appeals process increased trust among participants and improved retention.

## Case Study 3: Adaptive VR Workplace Simulation

**Key Points**
- University research project used AI to adjust simulation difficulty in real time
- Participants with traumatic brain injuries received personalized prompts
- Feedback from therapists shaped algorithm updates
- Study emphasized accessible design to avoid sensory overload

**Explanation**
Researchers developed a VR workplace simulator that modifies tasks based on user performance. To meet accessibility goals, all text alternatives and captions followed the repository's requirements. Therapists noted that adjustable pacing helped reduce cognitive strain. By combining human oversight with adaptive algorithms, the project demonstrated a successful approach to inclusive VR training.

## Case Study 4: Walmart's VR Training Program

**Key Points**
- Large retail chain partnered with Strivr to teach associates how to handle busy shopping days
- Training sessions collect performance metrics under a strict privacy policy
- Reported decrease in onboarding time and improved confidence among new hires

**Explanation**
Walmart rolled out headsets so employees could practice scenarios like Black Friday crowds. The company worked with Strivr to keep usage data anonymous and participation voluntary. Clear communication about metrics addressed surveillance concerns while still measuring effectiveness. [Strivr's case study](https://www.strivr.com/walmart-case-study/) provides additional details.

## Case Study 5: Bravemind PTSD Therapy

**Key Points**
- Developed by the University of Southern California's Institute for Creative Technologies
- Immersive environments help veterans revisit traumatic memories in a controlled setting
- Sessions require licensed clinicians and explicit informed consent

**Explanation**
Bravemind exposes participants to tailored VR scenes while therapists monitor reactions and adjust intensity. Ethical guidelines mandate voluntary participation and clinical oversight to minimize distress. Studies show meaningful symptom reduction for many veterans. More information is available on the [USC ICT website](https://ict.usc.edu/prototypes/bravemind/).

## Case Study 6: Harassment in Social VR Platforms

**Key Points**
- Testers in Meta's Horizon Worlds reported incidents of virtual harassment
- Platform responded by implementing personal boundary features
- Highlights the importance of clear community standards in VR spaces

**Explanation**
Early adopters of Horizon Worlds described unwanted contact from other avatars, prompting discussion about moderating social VR. Meta added safety tools like default distance buffers and easier reporting. This episode shows that ethical VR design must address user behavior along with technical accessibility. [The Verge](https://www.theverge.com/2021/12/16/22839010/meta-horizon-worlds-vr-harassment-virtual-reality) summarizes the controversy.

## Additional Links

- [Strivr Walmart Case Study](https://www.strivr.com/walmart-case-study/)
- [USC ICT Bravemind Project](https://ict.usc.edu/prototypes/bravemind/)
- [The Verge on Horizon Worlds Harassment](https://www.theverge.com/2021/12/16/22839010/meta-horizon-worlds-vr-harassment-virtual-reality)

- [Algorithm Tips: Resources and leads for investigating algorithms in society](https://algorithmstips.org/)
- [Awful AI: Curated list to track current scary usages of AI](https://github.com/daviddao/awful-ai)
- [Berkeley Haas Center for Equity, Gender, and Leadership: Bias in AI Examples Tracker](https://haas.berkeley.edu/egal/bias-in-ai-examples-tracker/)
- [CDEI: Review into bias in algorithmic decision-making](https://www.gov.uk/government/publications/cdei-review-into-bias-in-algorithmic-decision-making)
- [Digital Europe: Case Studies on Artificial Intelligence](https://www.digitaleurope.org/resources/case-studies-on-artificial-intelligence/)
- [Eticas Foundation: Observatory of Algorithms with Social Impact](https://observatory.algorithms.ngo/)
- [Fiesler, Casey & Garrett, Natalie & Beard, Nate. 2020. What Do We Teach When We Teach Tech Ethics?: A Syllabi Analysis](https://arxiv.org/abs/2001.07390)
- [Garrett, Natalie & Beard, Nate & Fiesler, Casey. 2020. More Than "If Time Allows": The Role of Ethics in AI Education](https://arxiv.org/abs/2004.12395)
- [Integrating Ethics within Machine Learning Courses – Saltz et al., 2019](https://doi.org/10.1145/3343032)
- [Harvard University: Justice case studies with Michael Sandel](https://justiceharvard.org/case-studies/)
- [IEEE - ECPAIS: Use Case – Criteria for Addressing Ethical Challenges in Transparency, Accountability, and Privacy of Contact Tracing (Draft)](https://standards.ieee.org/wp-content/uploads/import/documents/other/ecpais/ECPAI_Contract_Tracing_Use_Case.pdf)
- [Illinois Institute of Technology – Center for the Study of Ethics in the Professions: Ethics Case Studies Library](https://ethics.iit.edu/ecodes/)
- [MIT Media Lab: Moral Machine](https://www.moralmachine.net/)
- [National Center for Case Study Teaching in Science – Case Collection](https://sciencecases.lib.buffalo.edu/)
- [Santa Clara University, Markkula Center for Applied Ethics: Technology Ethics Cases](https://www.scu.edu/ethics/focus-areas/technology-ethics/resources/case-studies/)
- [OECD: AI Incidents Monitor (AIM)](https://oecd.ai/en/incidents)
- [Open Roboethics Institute: Scenario-based cases](https://www.openroboethics.org/research/)
- [Peltarion: Deep Learning Opportunities and Best Practice Report](https://peltarion.com/knowledge-center/white-paper/deep-learning-opportunities-and-best-practice)
- [Princeton University, Dialogues on AI & Ethics: Case study PDFs](https://aiethics.princeton.edu/case-studies)
- [Problematic Machine Behavior: A Systematic Literature Review of Algorithm Audits (CSCW 2021)](https://github.com/researchproject-team/problematic-machine-behavior)
- [Project Sherpa: Case study future scenarios](https://www.project-sherpa.eu/final-research-contract-scenario/)
- [University of Washington Tech Policy Lab: Designing Tech Policy – Instructional Case Studies for Technologists and Policymakers](https://techpolicylab.uw.edu/designing-tech-policy/)

